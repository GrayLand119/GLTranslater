Hello, and welcome back.
I just wanted to give you sort of a sense of the actual physical experience of
connecting and communicating and computing in the 60s and the 70s.
The 70s was when I got my start and the lucky people got to use teletype, like was
being used in that video, and other people used punch cards.
You also heard the squealing sound of the data being converted into sound
and back and forth. You know the key goal was there would
be, if you were lucky, one computer within a 20-mile radius of where you were sitting
so you could use a local phone call and you could be on all day and do things all
day long and that was really exciting and a lot of fun.
And this was sort of a common, if you were sort of, you know, today you have a
$2,000 laptop, the fancy people had these teletypes right in their office because
then they could conveniently sort of do computation, and not have to go
somewhere to do that computation. So that's pretty exciting.
So dial-up was kind of like the way the campus operated.
But you could also do data transfer with leased lines.
And the typical thing about leased lines is there the phone company that's going
between two cities digs a hole and puts a cable in and has some number of copper
wires in between those cities. This is back then, of course it's fiber
optic now, but back then it was copper. And every time you would make a call
between those two cities, it would have to find a free piece of wire and connect it
up so that your call, the audio of your call, would go through that wire.
And if you wanted to, you could pay them to lease one of those pieces of wire.
It meant that people couldn't use that wire for phone calls.
So you would sort of take it out of service. And if they 
had 500 wires between two cities and you leased one of them, then
they had 499 wires. And so it was rather expensive.
And really very importantly, the cost was based on distance, right?
A mile, versus five miles, versus 20 miles, versus 100 miles, the cost would kind of go up
linear based on distance. And so that's, that's a key thing that
distance is important in these very limited-resource copper wires where you
had to dedicate a wire either to a phone call or to data.
And so, we ended up evolving, in the academic world what we called store and
forward networking, with the sole purpose of compromising everything so that we
would keep our cost that we paid for our phone lines to a minimum.
We wanted to communicate in academia with people all around the country and all
around the world, so we had to keep the cost low. And so 
we would lease a leased line, you know, so here would be us sitting
with terminals in our offices and we would use dial-up to get connected and so this
might be a few miles, like 1 to 2 miles, or 1 to 2 kilometers.
And that's what you had to, you had to live near a computer or have an office
near a computer and then you would use the local telephone network to dial in
to do your work. And then there would be one connection out
the back of that computer to another computer that would
also have users on it, and then other computers with users on it, other
computers with users on it. So this might, for example, be Michigan,
this might be Stanford. Stanford would have a computer, Michigan
would have a computer. The Stanford people would be connected to the
Stanford computer. Stanford would have one little connection
off its back end and to the rest of the world.
So you sitting here want to talk to somebody sitting here, So this is how it
worked. You're sort of always connected so your
data would be inside, you know, you type an email into the computer and then you
would say, send that out to my colleague at Stanford, and so the problem is
everyone else was sending and so let's say for example that somebody sent a pretty
big thing. Big purple circle is what they're sending.
And then somebody next to you an office down sends a kind of medium-sized orange
circle. And they're sitting there being stored in the local computer. And then you
finally finish typing your email message and it's kind of a small
green circle. And now, the problem is,
you're in a line. The way this worked is the software would
keep a queue or a line of those who were going to use the line, and then it
would sort of start streaming this stuff out. And once it started, 
it just kept doing the same file, over and over and over.
Now if it died, it would just start from the beginning again.
And so, it takes some time for that thing to move across the network.
And then when it moved across the network, the next message in line would start to be
sent across the network. And it would use that link
come on, finish up, there we go. Okay. It takes a while 
for these things to move across the link.
And then finally, and this could be ten minutes later, finally it was your turn.
And your stuff would work its way through the network, and get to the next computer.
The problem is, once it's in that computer, you'd face the same problem,
because if all these messages are going from Michigan, oops, forgot to hit the
button thing, from Michigan to Stanford and they're all on the way, they got to go
through all these links, because there wasn't a direct connection, because the
direct connection to Stanford would be very expensive. And so we find ourselves
in a situation where if you're stored, you sat on these computers.
And if there was an outage of a network, or say this one, this might be hours.
You might be sitting on this computer for hours, on their disk drive, right?
Not even in their memory, you would be sitting on their disk drive for an hour,
and then finally this would come back or maybe this computer was down.
They would come back up and then the data would start flowing again.
So it was haphazard. I keeping telling you, it was awesome, it was just slow, it
was awesome but slow. So don't, don't, don't feel sorry for us,
we loved it, we enjoyed it, it was great talking to colleagues all over the world.
So we ended up with a network architecture that encouraged more hops,
which means it encouraged more latency. It encouraged the likelihood of getting
stuck behind something large as it worked its way through the network.
So if, for example, we were going to send a message from East Lansing to, say, the East
Coast somewhere, and we would have two connections maybe.
We would have a connection between Michigan State University in East Lansing
and Ann Arbor, and then we'd have a, the data would get stored and forwarded in
Ann Arbor and then it would get further sent to Cleveland.
And, if you think about it, the wire between Ann Arbor and Cleveland
goes like this. Right? They probably buried wires under
the ground. And if we could actually convince Toledo, the cost of the big wire
versus the cost of the two shorter wires, the cost of the two shorter wires is almost
exactly the cost of the big wire, because it's not really a big wire.
And so if we can convince Toledo to join our little club, then we don't increase
the cost of our communications because we're, it's about the same, right?
The wire length is about the same. But we've got one more school for the same cost.
And if you keep doing that, and you keep saying oh, well let's put a school here,
and put a school here, and put a school here, in the middle of the lake, and put a
school here, in the middle of a forest. The economics said that you could
connect more schools with effectively fixed cost by shortening the distance
every time you made a connection. And sometimes they would sort of make
two connections. But the way it often worked was, from the
perspective of this whole thing, is the data would sort of tend to go, you know, up
to some central location and then kind of fan back out from the central location.
And, and so these, it, there wasn't a lot of redundant links in this whole
situation. So we find ourselves in a situation where
we can save more money, saving money by just simply adding hops.
So in this environment we had a lot of email. Back in those days 
we didn't have a lot of images. Computers, you know, barely could
do upper and lower case sometimes. It was impressive when we finally got to
upper/lower case, let alone images. And so for the longest time everything we
did was very text-oriented. Sometimes we would send small files like
programs to each other, but it was either text. And these days, 
those are tiny, it's almost like SMS, right?
It's almost like the size of an SMS message was the size of a typical mail
message back in those days. Images, we didn't have computers that
could even display them and so it hardly mattered.
So, you focused your life on this one computer within a 20-mile radius and it
had this connection to like, a snake-like connection that sort of went over hill and
dale and through somewhere and it finally got to Stanford or wherever
your mail had to go. But again, it was awesome to be able to
sit at a keyboard and talk to people all over the world, even though
it took four hours. We didn't send as much email
back then. And a number of networks came up. One of them that became sort of
pretty widely used was a thing called Bitnet, and it was where everything kind
of came back to Princeton was one of the main hubs of Bitnet.
And it worked really well, and there was a way to say, oh, I need one more
school, and we'd go find the ones that are closest and we'd make the connection.
And so that's pretty much how the average academic saw networking.
One common campus computer and sort of this weird, slow, store-and-forward
networking that worked well enough. But during that exact same time, from the
1960s to the 1980s, the US Department of Defense was investing in a research
network called ARPANET. And ARPANET was funded by the military,
ARPA, Defense Advanced Research Projects Agency.
And later in the lecture we'll meet Vint Cerf, who will tell the
story much better that I can tell it, but I'll just tell you a short version
right now. A lot of people wonder why the Department
of Defense started this project and a lot of people say, oh it's because of fear
of nuclear war. And the project was very long, and there
were various motivations throughout the various phases of the effort.
But, if, based on what I've been told and what I've read, I think it's safe to say
that the primary motivation was to improve the use of their computing equipment that
they were using for military purposes, make it easier to access them, make it so
people didn't have to travel as much. It made it so that people could work from
their office on many different computers. And also so that people could actually
talk more effectively, so they could send email real fast, so that the email would
move faster for military people. So the first thing is really kind of an end
user focus to make them more useful to people and get people
working together more effectively.
That was the first kind of heavy motivation. The second motivation
was, actually had to do with reliably, reliability and redundancy
and resistance to partial failure. And that really wasn't so much about
nuclear attack, that was more about battlefield attack.
So the notion that once you start having all these links and you make them
wireless, and you put them in trailers on a battlefield, and, you know, you've got a
few hundred miles and the data's moving back and forth.
Then we have to worry about, in a battlefield situation, one of those
trailers might get hit. And how would you keep the network running
if one of those trailers got hit? So, the notion that we have sort of a
whole nation and we are worried about communications, I'm sure there was some
worry about that, but it wasn't really the main reason.
I mean, the exciting thing to me is the mean reason was a very
people-centered reason, of people working more effectively.
But this was a rather exclusive club, rather exclusive network, because it
was only for the people who were either military, or funded to build it.
So in 1969 there were four hosts on it. Again, that's research.
And these were leased lines, the same ones we were all using to do our email, and
they were expensive, very expensive. But because it was a large grant, they
just paid it because the research was not about the money.
The research was if you have these connections, what would be the best way to
use them and how to deal with redundancies, and how to deal with
multiple paths to the same place. All that stuff is interesting
research questions that computer scientists spent many years conceiving of.
And so by 1972, it looks like we got about 20. We got a couple of 
cross-country links and multiple connections, and this looks
like a great testbed to see, you know, so all of a sudden this part goes down, how
quickly can we reroute around the outage. And literally, these things these days
reroute around outages in far less than a second, and so that's really impressive.
Our current Internet owes its history to the research that was done in the
1960s and the 1970s. But what was fundamentally different between the
store-and-forward networks of Bitnet and this ARPANET research network was the notion of
packet switching. So the, it's a real simple concept.
It just takes a little more complex software to solve.
The store-and-forward network would start sending data across the link and then
keep sending it until it was done. That was seen to be very efficient.
You didn't want to like, you wanted to use it as fast as you can and then put the
next one out, and put the next one out, and put the next one out.
It was really simple and it dealt with outages in a simple manner by storing them
all locally on the disk. But what if instead you made it so you
broke every message Let me see if I can even draw this.
I should probably make a slide about this. So, if there's a network here, and here's
my computer and it's got a network connection, and it's got one really big
message, broken into pieces. Many pieces. And it sends the pieces one at a time.
If you show up with a really short message with only three pieces, all you have to do
is wait for one piece to go and then your piece goes in and then you share for a
while. Right. You share for a while and then yours
have made it through because you only have three packets. This has 
like 1,000 packets. And then once your message is through, they resume
sending this data in order. And so you were able to sneak and bypass
the traffic jam that was this large amount of data.
And so, that's the idea of packets. And packets are these chunks to say,
what we're going to send is a piece, and then at the end of that we're going to
maybe send a piece of a different message. It was allowing simultaneously multiple
messages to be in flight at the same time. That's packet switching.
And what happened then is we also ended up with these special-purpose computers
called routers. They're still computers, but they weren't
doing storing in the same way. They were just forwarding, they weren't
store-and-forward, they were merely forwarding. So we'll get back to that in a second.
So my favorite analogy to talk about how packets work is postcards.
So let's say that I want to send a 30-character message to my friend 
Daphne at Stanford, but all I have is 10-character postcards.
So, off I go. I break my message into
three bits of 10 characters. I write each piece on a 
different postcard. I address with a from and a to address,
from Chuck to Daphne, and then I give a sequence number so that when she gets the
postcards she knows what order to put them back together.
So I have to label each of these. And these are fixed width,
fixed length. They, you know, it's like a packet, right?
I'm breaking a long message that might be very long into nothing, so that each
piece is a certain size so that we can all share it, right?
And so then what I do is I send these, I put them all in my mailbox.
And then I wait and this magical thing called the Post Office picks them up, puts
them in buildings, people sort them. They end up on trucks, they end up on
planes, on trains, on donkeys, by hand. And each of my postcards might take a
different route. I mean one of my postcards, I'll show you
on a map here, now one of my postcards, nope not that one, let's do that.
One of my postcards, you know, goes from Michigan to Chicago to Kansas City to San
Francisco. Another of my postcards goes from
Michigan, to Chicago, to Dallas, to Denver, to Kansas City, to Chicago, to San
Francisco. And my third postcard goes really crazy,
it goes to Cleveland, then it goes to Atlanta, then it goes to Washington D.C.
And then it goes to Chicago, and then it goes to Kansas City, and then it makes it
to San Francisco. Now the fact that they took different
paths and they might not even arrive in order, some might get past each other,
they might get stuck somewhere. It doesn't matter, because each one of
these has been labelled both with the from and the to destination.
So each of these intermediate locations doesn't have to get it to the final
destination, they just have to get it closer. They make choices and
even if they make the wrong choice, it can be sort of dealt
with one way or the other, okay? So, this is some big mystery,
it's called the Post Office. It just takes these little cards with labels and
moves them. It doesn't know if that's a YouTube video or if it's an email, it doesn't
really care, it just has these little chunks to move around that have
from and to addresses. And that's the essence of the network, the
Internet, the cloud. That's why we draw this picture, you'll see
like, ooh, it's a cloud, and that's because it's, don't worry about what's
inside here, it's all super mysterious and don't worry about it, it just comes out.
So after all that happens, Daphne, who happens to have the exact same 
mailbox as I do, kind of rare. We both have a mailbox that's
copyright Creative Commons. That's what's cool about this mailbox.
At some point later these things start appearing. She goes like, 
whoa, looks like Chuck is sending me a note. But because of 
his limitation of postcards he's only sent me one.
I know who it's from and I know who it's to, and I know that's the first of some
number of messages. And then the next day out comes another one,
because that was the one that sort of, went the more southerly route.
And she goes, well I'm missing something, I'll just sit and wait and 
see what happens. And then finally, many, many days later,
the one that took the circuitous, cir-, most circuitous, most
roundabout route comes and now Daphne can reassemble the
messages because she has the sequences. So she simply puts them back together.
1, 2, 3, boom. So she puts them back together, she has
it, she sort of throws the post cards away and she has the ultimate final message.
That's packets. Packets are breaking a big message into
small parts, labeling each one of them individually, and then throwing 
them into the shared network. And so this is what it looks like.
The Post Office in this is called a gateway.
Okay. Come on.
Gateway. Okay.
So, that's a gateway. So, here's Michigan, here's Stanford.
Stanford has a gateway too, that's like their Post Office.
In the middle is the Post Office box. Right? And the Post Office has intermediate locations.
And it has trucks and locations. These are links and routers.
And messages can take different paths.
Right? And then they arrive and they're
reassembled. And we have, like, the ability to hook
from home, and stuff like that. So there's a local area network, LAN,
and there's this sort of like Internet, the network of networks.
It's like the Post Office. And it still breaks things into packets,
they still come out as packets, and then Daphne has to reassemble them on her
computer to create the message. So, it, so the research network ARPANET
solved a lot of engineering problems, and that was sort of what they did.
So here is an example problem to solve. Now, none of the mailbox, none of the
routers, none of the post offices, know exactly where the thing is going.
And they don't transport it to the final destination. All they do is 
they transport it to the future, to a further down destination.
But what if they get it wrong? What if one, this is like Michigan, this
is Chicago, this is Dallas. And what if Michigan thinks sending to
Chicago is a good idea? Chicago thinks sending to Dallas is a good
idea. And then Dallas thinks sending it to
Michigan is a good idea. Well, then Michigan's going to get it again
and send it back to Chicago. And so then what you end up with is this
situation where your packet, your data, is in a loop, right?
This wouldn't be good for the Post Office and it's not good for the Internet.
So, you have to say, how do we solve this problem when something's wrong, right? It's, you, you wish it were perfect,
but it's not. And so this is the kind of research
question, as to how to solve this kind of problem, and we'll talk more about this in
a bit when we get into a little more technical detail.
But I just wanted to sort of say, that's the kind of research and engineering that
took literally 20 years, and four different versions of it, of the ARPANET
to get right. And so, by the end of the 1970s there was
quite a sophisticated network. Like I said, they'd rewritten it
four times. It had gotten to be very sophisticated, it
had been a good investment. They had been careful about understanding
how to improve it each time they rebuilt it.
And so it was really a fine working piece of software, and the people
who used it at these research universities and at the military, it was kind of
like a futuristic world, right, you could send email and a second later it would
appear, right. It was really quick and everything was nice and you could even
have instant message-like interactions where it went right then. And the 
problem was that this is a small group of people. This is maybe, 
looks like 60 or so. That was all the computers on the entire
Internet, right? I mean now we have our cell phones and we
have billions of them, right? But this is like 60. And so a 
real question is how did this go from 60 computers of a very narrow group
to a much larger group. And the answer to that question is at
Urbana-Champaign, Illinois. And so, at the same time that, this kind
of goes back to Bletchley Park, right, where the computers were part of science.
Throughout the 50s and 60s and 70s scientists, much like the military, were
realizing computers were mighty useful to advance scientific research.
And so the National Science Foundation would fund universities to buy computers,
and they'd say give me ten million dollars to buy a computer.
And another university would be like, give me ten million dollars to buy a computer.
And then three years later the first university says, my computer is obsolete,
I need another ten million dollars. Now the research questions were good
research questions. And they were important to society.
But the National Science Foundation got tired of giving ten million dollars to
every, everybody who. Wait, hang on a sec, let me...
As a matter of fact, I was part of this because I used to be a high-performance
computer guy. This is a Convex C3800 supercomputer.
I would be about this tall on this supercomputer, this is a lovely and very
expensive model that I was given after, afterwards, and I wouldn't throw it away
because this was from, like, 1987. And basically I wanted one of these
terribly badly. Each one of these is about two million
dollars, so this is like two, four, six, eight, ten million dollars.
And I so badly wanted this, and I thought that I deserved a ten-million-dollar
toy, and I could do such great research. But unfortunately everybody else wanted
the exact same thing. And they were important, too.
So the National Science Foundation said to themselves hey, this isn't going to work
very well if I can't find my pen. You know, we're not going to be able to,
we're going to make a network. How about we put a few of these things in,
and then make a network and connect them together. Of course it's 
never as simple as that. So now we're going to meet Larry Smarr, at
the National Center for Supercomputing Applications, N-C-S-A, at the University
of Illinois Urbana-Champaign. And Larry was the director of NCSA and
one of the many people, but one of the most instrumental people, in creating
the national network that we now think of as the Internet, and getting it moving it
from being a research project to being a project that we all, both academics and
regular people, that we all can make really good use of. And so let's take a
look at Larry Smarr.